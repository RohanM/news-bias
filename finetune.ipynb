{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW, SGD\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    \"\"\"A neural network layer that applies the specified function to its inputs.\"\"\"\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(x):\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "def flatten(x):\n",
    "    return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    EMBEDDING_SIZE = 16\n",
    "    HIDDEN_SIZE = 512\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_tokens, vocab_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, self.EMBEDDING_SIZE),\n",
    "            Lambda(flatten),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(num_tokens*self.EMBEDDING_SIZE, self.HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.HIDDEN_SIZE, self.HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.HIDDEN_SIZE, 1),\n",
    "        )\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.model.to(device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(input_ids)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss(outputs, labels)\n",
    "    \n",
    "        return SequenceClassifierOutput(loss=loss, logits=outputs)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        state = torch.load(path)\n",
    "        self.model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressiveTransformer(nn.Module):\n",
    "    TRANSFORMER_HIDDEN_SIZE = 768\n",
    "    LINEAR_HIDDEN_SIZE = 500\n",
    "    \n",
    "    def __init__(self, num_tokens):\n",
    "        super(RegressiveTransformer, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(checkpoint)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.TRANSFORMER_HIDDEN_SIZE, self.LINEAR_HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.LINEAR_HIDDEN_SIZE, 1),\n",
    "            Lambda(flatten),\n",
    "            nn.Linear(num_tokens, 1),\n",
    "            Lambda(flatten),\n",
    "            Lambda(lambda x: x.squeeze())\n",
    "        )\n",
    "        \n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.base_model.to(device)\n",
    "        self.head.to(device)\n",
    "        \n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        outputs = self.head(outputs[0])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss(outputs, labels)\n",
    "    \n",
    "        return SequenceClassifierOutput(loss=loss, logits=outputs)\n",
    "    \n",
    "    def freeze_base(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_base(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def save(self, path):\n",
    "        checkpoint = {\n",
    "            'base': self.base_model.state_dict(),\n",
    "            'head': self.head.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.base_model.load_state_dict(checkpoint['base'])\n",
    "        self.head.load_state_dict(checkpoint['head'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"Left left left\",\n",
    "    \"Right right right\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2187, 2187, 2187,  102],\n",
       "        [ 101, 2157, 2157, 2157,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = inputs['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressiveTransformer(num_tokens)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.logits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1557, -1.5389,  0.1895, -0.7843,  0.1395],\n",
       "        [ 0.2366,  0.2738, -0.2696, -0.0122,  2.6147],\n",
       "        [-1.9680,  0.0860, -1.3859, -1.5596,  1.6392]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = nn.Embedding(3, 5)\n",
    "e.forward(torch.tensor([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_inputs), num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1613],\n",
      "        [-0.1300]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(num_tokens, tokenizer.vocab_size)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.logits.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep training/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6cf03802fe7c5a12\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0)\n",
      "Using custom data configuration default-6cf03802fe7c5a12\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Trial data\n",
    "data_train = Dataset.from_csv('data/trial.csv')\n",
    "data_valid = Dataset.from_csv('data/trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-daa4a8e33107a876\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-daa4a8e33107a876/0.0.0)\n",
      "Using custom data configuration default-0f73ba8ec2b92be8\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-0f73ba8ec2b92be8/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Mini data\n",
    "data_train = Dataset.from_csv('data/train-mini.csv')\n",
    "data_valid = Dataset.from_csv('data/valid-mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-16496940b3cae9e5\n",
      "Reusing dataset csv (/home/.cache/huggingface/datasets/csv/default-16496940b3cae9e5/0.0.0)\n",
      "Using custom data configuration default-7fec7a7bbca81e52\n",
      "Reusing dataset csv (/home/.cache/huggingface/datasets/csv/default-7fec7a7bbca81e52/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Full data\n",
    "data_train = Dataset.from_csv('data/train.csv')\n",
    "data_valid = Dataset.from_csv('data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sample):\n",
    "    return tokenizer(sample['text'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0/cache-f2b53b9cbdfcf85d.arrow\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0/cache-f2b53b9cbdfcf85d.arrow\n"
     ]
    }
   ],
   "source": [
    "data_valid = data_valid.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.remove_columns(['text'])\n",
    "data_valid = data_valid.remove_columns(['text'])\n",
    "data_train = data_train.rename_column('rating', 'labels')\n",
    "data_valid = data_valid.rename_column('rating', 'labels')\n",
    "data_train.set_format('torch')\n",
    "data_valid.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    data_train,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    data_valid,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = data_train['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 30522)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader, valid_dataloader, lr=0.00001, acc_thresh=0.1):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        self.acc_thresh = acc_thresh\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    def train(self, num_epochs, max_batches=None):\n",
    "        num_train_batches = min(len(self.train_dataloader), max_batches or float('inf'))\n",
    "        num_valid_batches = min(len(self.valid_dataloader), max_batches or float('inf'))\n",
    "        num_train_steps = num_epochs * num_train_batches\n",
    "        num_valid_steps = num_epochs * num_valid_batches\n",
    "        self.lr_scheduler = self.__get_scheduler(num_train_steps)\n",
    "        \n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        \n",
    "        self.train_progress = tqdm(range(num_train_steps))\n",
    "        self.train_progress.set_description('Training')\n",
    "        self.valid_progress = tqdm(range(num_valid_steps))\n",
    "        self.valid_progress.set_description('Validation')\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_losses = self.__train(max_batches)\n",
    "            epoch_accuracies = self.__eval(max_batches)\n",
    "            losses.append(np.mean(epoch_losses))\n",
    "            accuracies.append(np.mean(epoch_accuracies))\n",
    "        \n",
    "        return {\n",
    "            'losses': losses,\n",
    "            'accuracies': accuracies,\n",
    "        }\n",
    "\n",
    "    def __train(self, max_batches=None):\n",
    "        losses = []\n",
    "        model.train()\n",
    "        for i, batch in enumerate(self.train_dataloader):\n",
    "            if max_batches and i >= max_batches: break\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            outputs = self.model(**batch)\n",
    "            loss = outputs.loss\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self.lr_scheduler.step()\n",
    "            self.train_progress.update(1)\n",
    "        return losses\n",
    "\n",
    "    def __eval(self, max_batches=None):\n",
    "        accuracies = []\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(self.valid_dataloader):\n",
    "            if max_batches and i >= max_batches: break\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "            diffs = (batch['labels'] - outputs.logits).abs()\n",
    "            num_correct = torch.count_nonzero(diffs.where(diffs < self.acc_thresh, torch.zeros_like(diffs)))\n",
    "            accuracies.append((num_correct / float(batch['labels'].shape[0])).cpu())\n",
    "            self.valid_progress.update(1)\n",
    "        return accuracies\n",
    "\n",
    "    def __get_scheduler(self, num_training_steps):\n",
    "        return get_scheduler(\n",
    "            \"cosine\",\n",
    "            optimizer=self.optimizer,\n",
    "            num_warmup_steps=50,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, smoothing_window=50):\n",
    "    window = [1/smoothing_window] * smoothing_window\n",
    "    plt.plot(np.convolve(results['losses'], window, 'valid'))\n",
    "    plt.plot(np.convolve(results['accuracies'], window, 'valid'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(model, dataset):\n",
    "    outputs = model(dataset['input_ids'], attention_mask=None).logits.squeeze().detach()\n",
    "    int_outputs = (outputs * 2).round().int().clamp(-2, 2)\n",
    "    int_labels = (data_valid['labels'] * 2).int()\n",
    "    return confusion_matrix(int_labels, int_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    n_total = sum(sum(matrix))\n",
    "    n_acc = sum([matrix[i, i] for i in range(len(matrix))])\n",
    "    acc = int(n_acc / float(n_total) * 100)\n",
    "    print(f\"{n_acc} / {n_total} = {acc}%\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix)#, display_labels=[-2, -1, 0, 1, 2])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RegressiveTransformer(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(num_tokens, tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64310a7c7b19431a9fcf85b1d89d922f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c03a1409ee47c19a1183fd70ea3355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanmitchell/.local/share/virtualenvs/news-bias-nmNsirUF/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model, train_dataloader, valid_dataloader, lr=0.0001, acc_thresh=0.25)\n",
    "results = trainer.train(1)\n",
    "all_results.append(results)\n",
    "plot_results(results, 1)\n",
    "cms.append(build_confusion_matrix(model, data_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5 = 20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cm in cms:\n",
    "    plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanmitchell/.local/share/virtualenvs/news-bias-nmNsirUF/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.5009, grad_fn=<MseLossBackward0>), logits=tensor([[-0.0090],\n",
       "        [ 0.0200],\n",
       "        [-0.0218],\n",
       "        [ 0.0396],\n",
       "        [-0.0457]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dataloader))#.to('cuda')\n",
    "model(**batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up:\n",
    "- [ ] Hyperparameters - try a higher LR\n",
    "- [ ] Tooling to report with larger batch size (ie. full data)\n",
    "- [ ] Match up train and eval reporting size\n",
    "\n",
    "What kind of visualisation approach could we use?\n",
    "\n",
    "- The most natural would be to average stats per-epoch\n",
    "- That's not very practical with our dataset size\n",
    "- We could put a limit on num batches per epoch\n",
    "- Since they're shuffled, we'll get a different sample of the data each time\n",
    "- Then set a number of epochs to get the amount of training we desire\n",
    "- Keep the validation set consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
