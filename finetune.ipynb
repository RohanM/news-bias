{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import AdamW, SGD\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    \"\"\"A neural network layer that applies the specified function to its inputs.\"\"\"\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(x):\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "def flatten(x):\n",
    "    return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressiveTransformer(nn.Module):\n",
    "    TRANSFORMER_HIDDEN_SIZE = 768\n",
    "    LINEAR_HIDDEN_SIZE = 500\n",
    "    \n",
    "    def __init__(self, num_tokens):\n",
    "        super(RegressiveTransformer, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(checkpoint)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.TRANSFORMER_HIDDEN_SIZE, self.LINEAR_HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.LINEAR_HIDDEN_SIZE, 1),\n",
    "            Lambda(flatten),\n",
    "            nn.Linear(num_tokens, 1),\n",
    "            Lambda(flatten),\n",
    "            Lambda(lambda x: x.squeeze())\n",
    "        )\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        outputs = self.head(outputs[0])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss(outputs, labels)\n",
    "    \n",
    "        return SequenceClassifierOutput(loss=loss, logits=outputs)\n",
    "    \n",
    "    def freeze_base(self, freeze=True):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = not freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"Left left left\",\n",
    "    \"Right right right\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = inputs['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressiveTransformer(num_tokens)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we started with a batch of our sentence inputs, and we now have a continuous value for each.\n",
    "\n",
    "Next, we need some data to fine tune on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alright, we have a csv with all this data\n",
    "- We also need to bring in the media bias ratings\n",
    "\n",
    "- Then we want a way to read from the CSV and generate as much training data as we want\n",
    "- Let's look at some of the other data sets to look at the rough size that you'd use to finetune BERT\n",
    "  - Looks like 10-100k rows\n",
    "\n",
    "- I could preprocess this into a new CSV file with all the info condensed\n",
    "- Validation set should include articles from publications not in the train set\n",
    "- Evaluate accuracy based on whether predicted result is within delta of labelled value\n",
    "  - Maybe delta starts pretty large, say 0.5 or 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What data set do we need to establish the pipeline?\n",
    "\n",
    "CSV of article => rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "\n",
    "- [ ] Prepare real data CSV\n",
    "- [ ] Set up DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('data/trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list(articles.title + ' ' + articles.article)\n",
    "ratings = torch.tensor(articles.rating).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['labels'] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = batch['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressiveTransformer(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "optimizer = SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    results = model(**batch)\n",
    "    all_results.append(results.logits.tolist())\n",
    "    results.loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
