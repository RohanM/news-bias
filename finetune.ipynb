{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW, SGD\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prep training/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6cf03802fe7c5a12\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0)\n",
      "Using custom data configuration default-6cf03802fe7c5a12\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Trial data\n",
    "data_train = Dataset.from_csv('data/trial.csv')\n",
    "data_valid = Dataset.from_csv('data/trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-daa4a8e33107a876\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-daa4a8e33107a876/0.0.0)\n",
      "Using custom data configuration default-0f73ba8ec2b92be8\n",
      "Reusing dataset csv (/Users/rohanmitchell/.cache/huggingface/datasets/csv/default-0f73ba8ec2b92be8/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Mini data\n",
    "data_train = Dataset.from_csv('data/train-mini.csv')\n",
    "data_valid = Dataset.from_csv('data/valid-mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-16496940b3cae9e5\n",
      "Reusing dataset csv (/home/.cache/huggingface/datasets/csv/default-16496940b3cae9e5/0.0.0)\n",
      "Using custom data configuration default-7fec7a7bbca81e52\n",
      "Reusing dataset csv (/home/.cache/huggingface/datasets/csv/default-7fec7a7bbca81e52/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Full data\n",
    "data_train = Dataset.from_csv('data/train.csv')\n",
    "data_valid = Dataset.from_csv('data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def encode(sample):\n",
    "    return tokenizer(sample['text'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0/cache-f2b53b9cbdfcf85d.arrow\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/rohanmitchell/.cache/huggingface/datasets/csv/default-6cf03802fe7c5a12/0.0.0/cache-f2b53b9cbdfcf85d.arrow\n"
     ]
    }
   ],
   "source": [
    "data_valid = data_valid.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train.remove_columns(['text'])\n",
    "data_valid = data_valid.remove_columns(['text'])\n",
    "data_train = data_train.rename_column('rating', 'labels')\n",
    "data_valid = data_valid.rename_column('rating', 'labels')\n",
    "data_train.set_format('torch')\n",
    "data_valid.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    data_train,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    data_valid,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_tokens = data_train['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 30522)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    \"\"\"A neural network layer that applies the specified function to its inputs.\"\"\"\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_shape(x):\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "def flatten(x):\n",
    "    return x.view(x.shape[0], -1)\n",
    "\n",
    "def squeeze(x):\n",
    "    return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    EMBEDDING_SIZE = 16\n",
    "    HIDDEN_SIZE = 512\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_tokens, vocab_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, self.EMBEDDING_SIZE),\n",
    "            Lambda(flatten),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(num_tokens*self.EMBEDDING_SIZE, self.HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.HIDDEN_SIZE, self.HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(self.HIDDEN_SIZE, 1),\n",
    "            Lambda(squeeze),\n",
    "        )\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.model.to(device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(input_ids)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss(outputs, labels)\n",
    "    \n",
    "        return SequenceClassifierOutput(loss=loss, logits=outputs)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        state = torch.load(path)\n",
    "        self.model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RegressiveTransformer(nn.Module):\n",
    "    TRANSFORMER_HIDDEN_SIZE = 768\n",
    "    LINEAR_HIDDEN_SIZE = 500\n",
    "    \n",
    "    def __init__(self, num_tokens):\n",
    "        super(RegressiveTransformer, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(checkpoint)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.TRANSFORMER_HIDDEN_SIZE, self.LINEAR_HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.LINEAR_HIDDEN_SIZE, 1),\n",
    "            Lambda(flatten),\n",
    "            nn.Linear(num_tokens, 1),\n",
    "            Lambda(flatten),\n",
    "            Lambda(lambda x: x.squeeze())\n",
    "        )\n",
    "        \n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.base_model.to(device)\n",
    "        self.head.to(device)\n",
    "        \n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        outputs = self.head(outputs[0])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss(outputs, labels)\n",
    "    \n",
    "        return SequenceClassifierOutput(loss=loss, logits=outputs)\n",
    "    \n",
    "    def freeze_base(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_base(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def save(self, path):\n",
    "        checkpoint = {\n",
    "            'base': self.base_model.state_dict(),\n",
    "            'head': self.head.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.base_model.load_state_dict(checkpoint['base'])\n",
    "        self.head.load_state_dict(checkpoint['head'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"Left left left\",\n",
    "    \"Right right right\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2187, 2187, 2187,  102],\n",
       "        [ 101, 2157, 2157, 2157,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_tokens = inputs['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = RegressiveTransformer(num_tokens)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.logits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1557, -1.5389,  0.1895, -0.7843,  0.1395],\n",
       "        [ 0.2366,  0.2738, -0.2696, -0.0122,  2.6147],\n",
       "        [-1.9680,  0.0860, -1.3859, -1.5596,  1.6392]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = nn.Embedding(3, 5)\n",
    "e.forward(torch.tensor([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_inputs), num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1613],\n",
      "        [-0.1300]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(num_tokens, tokenizer.vocab_size)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.logits.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader, valid_dataloader, lr=0.00001, acc_thresh=0.1):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        self.acc_thresh = acc_thresh\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    def train(self, num_epochs, max_batches=None):\n",
    "        num_train_batches = min(len(self.train_dataloader), max_batches or float('inf'))\n",
    "        num_valid_batches = min(len(self.valid_dataloader), max_batches or float('inf'))\n",
    "        num_train_steps = num_epochs * num_train_batches\n",
    "        num_valid_steps = num_epochs * num_valid_batches\n",
    "        self.lr_scheduler = self.__get_scheduler(num_train_steps)\n",
    "        \n",
    "        outputs = []\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        \n",
    "        self.train_progress = tqdm(range(num_train_steps))\n",
    "        self.train_progress.set_description('Training')\n",
    "        self.valid_progress = tqdm(range(num_valid_steps))\n",
    "        self.valid_progress.set_description('Validation')\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_losses = self.__train(max_batches)\n",
    "            epoch_outputs, epoch_accuracies = self.__eval(max_batches)\n",
    "            outputs.extend(epoch_outputs)\n",
    "            losses.append(np.mean(epoch_losses))\n",
    "            accuracies.append(np.mean(epoch_accuracies))\n",
    "        \n",
    "        return {\n",
    "            'outputs': outputs,\n",
    "            'losses': losses,\n",
    "            'accuracies': accuracies,\n",
    "        }\n",
    "\n",
    "    def __train(self, max_batches=None):\n",
    "        losses = []\n",
    "        model.train()\n",
    "        for i, batch in enumerate(self.train_dataloader):\n",
    "            if max_batches and i >= max_batches: break\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            outputs = self.model(**batch)\n",
    "            loss = outputs.loss\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self.lr_scheduler.step()\n",
    "            self.train_progress.update(1)\n",
    "        return losses\n",
    "\n",
    "    def __eval(self, max_batches=None):\n",
    "        accuracies = []\n",
    "        all_outputs = []\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(self.valid_dataloader):\n",
    "            if max_batches and i >= max_batches: break\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "\n",
    "            all_outputs.append(outputs.logits.squeeze().tolist())\n",
    "            \n",
    "            diffs = (batch['labels'] - outputs.logits).abs()\n",
    "            num_correct = torch.count_nonzero(diffs.where(diffs < self.acc_thresh, torch.zeros_like(diffs)))\n",
    "            accuracies.append((num_correct / float(batch['labels'].shape[0])).cpu())\n",
    "            self.valid_progress.update(1)\n",
    "        return (all_outputs, accuracies)\n",
    "\n",
    "    def __get_scheduler(self, num_training_steps):\n",
    "        return get_scheduler(\n",
    "            \"cosine\",\n",
    "            optimizer=self.optimizer,\n",
    "            num_warmup_steps=50,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, smoothing_window=50):\n",
    "    window = [1/smoothing_window] * smoothing_window\n",
    "    plt.plot(np.convolve(results['losses'], window, 'valid'))\n",
    "    plt.plot(np.convolve(results['accuracies'], window, 'valid'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outputs(results):\n",
    "    plt.plot(results['outputs'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(model, dataset):\n",
    "    outputs = model(dataset['input_ids'], attention_mask=None).logits.squeeze().detach()\n",
    "    int_outputs = (outputs * 2).round().int().clamp(-2, 2)\n",
    "    int_labels = (data_valid['labels'] * 2).int()\n",
    "    return confusion_matrix(int_labels, int_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    n_total = sum(sum(matrix))\n",
    "    n_acc = sum([matrix[i, i] for i in range(len(matrix))])\n",
    "    acc = int(n_acc / float(n_total) * 100)\n",
    "    print(f\"{n_acc} / {n_total} = {acc}%\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=matrix)#, display_labels=[-2, -1, 0, 1, 2])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RegressiveTransformer(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(num_tokens, tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088863f3dd974c2bace8272c59ef792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd431352813747e4b1d1b4c9fcf922ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display outputs over training\n",
    "trainer = Trainer(model, train_dataloader, valid_dataloader, lr=0.001, acc_thresh=0.25)\n",
    "results = trainer.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = results['outputs']\n",
    "outputs = [e for e in outputs if len(e) == 8]\n",
    "\n",
    "plt.plot(outputs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(results, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d3148b9a8e4c56b3038f5f86f57d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a05e39c70143a983c6dc7a78532009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model, train_dataloader, valid_dataloader, lr=0.0001, acc_thresh=0.25)\n",
    "results = trainer.train(100)\n",
    "all_results.append(results)\n",
    "plot_results(results, 1)\n",
    "cms.append(build_confusion_matrix(model, data_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm in cms:\n",
    "    plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [CLS] spicer : conway was joking about spying microwaves. white house counselor kellyanne conway was joking when she spoke about that ’ s according to press secretary sean spicer, who said conway ’ s comment about microwaves that could take covert photos was made in “ jest. ” conway had told an interviewer that “ you can surveil someone through their phones, certainly through their television sets — any number of different ways — microwaves that turn into cameras. ” the comments were made in reference to claims president trump made about president obama conway in an interview monday on cnn — but didn ’ t say anything about joking. “ i was reflecting what people saw in the news last week, which were several articles about how we can surveil each other generally, ” conway said. asked on tuesday at his daily press briefing whether trump believed in using microwaves for surveillance, spicer said it was “ not a sound way of surveilling someone ” and said his white house colleague had made the comments in jest. spicer did, however, add that trump does still believe “ that there was surveillance conducted in the 2016 election, ” but failed to provide evidence to back up the president ’ s assertion. the white house has called on congress to. the first hearing on the subject on capitol hill is scheduled for next week. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "0.0 [CLS] lyft says, ‘ me too! ’ and dives into the self - driving game. conventional wisdom on self - driving used to go like this : a smart tech company, like google's waymo, writes the self - driving software. a smart chip company, like nvidia, provides the computing power. a smart automotive supplier, like delphi, brings the car parts. a smart carmaker, like gm, furnishes the cars — and everything runs on the platform created by a smart ride - hailing company, like uber or lyft. this line of thinking explains why players in this industry are partnering up like their survival depends on it. in the stage production that is getting you from a to b in a robocar, everyone plays a role. but some of these companies want bigger parts than others. today, lyft announced it ’ s getting into the self - driving business, launching its own unit to build autonomous vehicle software and hardware. “ it ’ s too strategic an area for us to not be a player, ” says luc vincent, the ex - google streetview - er who will head up the initiative's technical side. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "-0.5 [CLS] what ’ s next for this couple who won $ 500 million at powerball? work on monday.. the tennessee couple who bought one of the three grand powerball tickets plans to return to work on monday. because, well, “ why not? ” despite their newfound wealth — a $ 529 million prize — john and lisa robinson revealed few grand plans for the money at a friday afternoon news conference. in response to question after question, the pair seemed determined to mostly continue living life as they always have. when asked how they planned to spend the money, lisa responded first : they would pay down their daughter ’ s student loan debt. [ how powerball manipulated the odds to create a $ 1. 5 billion jackpot ] but surely they planned to splurge on something, a reporter suggested. “ my family, ” lisa said. would they at least move into a big, new house? “ we don ’ t need that, ” john said. “ i ’ ve never wanted that in the past, i don ’ t want that now, ” lisa added. they announced plans to return to work on monday. why? “ why not? ” lisa asked back. “ that ’ s what we ’ ve done all our lives, ” john said. the pair said on friday that they plan to claim their share of the world record $ 1. 58 billion powerball jackpot in one lump sum, roughly $ 328 million after taxes — money won with a ticket bought on the final day of sales. [ the states that rely on powerball and lotteries the most ] “ i was on my way home from work that day — this was the 13th — and she told me, she said you ’ ve got to pick us up a couple of lottery tickets, ” john robinson said. he wasn ’ t feeling well, but he stopped at the store anyway. he picked up a few tickets, came home and put them on the table for his wife. after the numbers were announced, lisa robinson was the first to realize they had won. “ i was running down the hallway screaming and crying, ” she said. she woke her husband out of a deep sleep to confirm that they indeed held a winning ticket. once confirmed, john wasted little time reaching out to his eldest brother to seek out help in finding legal and financial professionals to work with. [ a scandal is forgotten as powerball fever sweeps the united states ] “ he does investments, ” john said simply. despite all of the hoopla, though, the robinsons [SEP]\n",
      "0.0 [CLS] don ’ t blame pigs for swine flu — species hopping is how viruses evolve. when new species evolve, where do their viruses come from? as little more than free - ranging bundles of genetic material, viruses desperately need to hijack their hosts ’ cellular machinery and resources to replicate, over and over again. without its host, a virus is nothing. because of that dependence, some viruses have stuck with their hosts throughout evolution, mutating to make minor adjustments every time the host branched into a new species — a process called co - divergence. humans and chimpanzees, for instance, have slightly different versions of the hepatitis b virus, both of which likely mutated from a version that infected their shared ancestor more than four million years ago. the other option — cross - species transmission — occurs when a virus jumps into a completely new type of host largely unrelated to its former one. that kind of viral evolution is notoriously linked to severe emerging diseases like bird flu, hiv, ebola fever and sars. given the extreme virulence of those diseases, the apparent rarity of cross - species transmission seemed fortunate. but recently, when researchers in australia conducted the first study of the long - term evolution of thousands of diverse viruses, they reached a startling conclusion : cross - species transmission has been more important and more frequent than anyone realized. jumps between species have driven most major evolutionary innovations in the viruses. meanwhile, co - divergence has been less common than was assumed and has mostly caused incremental changes. “ they showed rather convincingly that co - divergence is the exception rather than the rule, ” said pleuni pennings, an evolutionary biologist and assistant professor at san francisco state university who was not involved with the study. the finding does not necessarily mean that emerging diseases from cross - species transmission are a more grave or imminent threat than medical science has assumed. however, it does reveal that the dynamics of virus evolution can be surprisingly complex. if scientists have been underestimating how often viruses can move into new hosts, then understanding which viruses are most primed to do so becomes a higher priority. there ’ s no shortage of reasons why cross - species jumps would seem unlikely to influence viral evolution much. the odds against a virus leaping successfully to a new host species are formidable. if the virus can ’ t manipulate the host ’ s genetic material and replicate itself, then that ’ s the end of the line. a virus might need to make multiple attempts to infect a novel host over decades or longer [SEP]\n",
      "1.0 [CLS] man accused of beating grandma to death found unfit to stand trial. while she was to a chair last september has been found unfit to stand trial in his other attempted murder case. gary bias was out on bail following the attempted murder of his stepfather, ahmed green, with a mini baseball bat in the fall of 2015 when he allegedly bias at her home. the did not appear in brooklyn court monday as it was revealed he ’ d been committed to a state facility for further evaluation and treatment. his family was not present for the announcement. bias ’ mother, alisha green, sprung him on $ 10, 000 in 2015 after he failed to kill her husband, making way for the oct. 2016 bloodbath. the unhinged man purportedly robbed his before binding and fatally beating her, cops said. he then lured his mother to the scene, bound her to a chair, and attempted to kill her too, but she managed to escape. bias will return to court for a special hearing in april. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data makes sense\n",
    "data = data_valid[:5]\n",
    "labels = data['labels']\n",
    "text = tokenizer.batch_decode(data['input_ids'])\n",
    "[print(e[0].item(), e[1]) for e in zip(labels, text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.5494, grad_fn=<MseLossBackward0>), logits=tensor([-0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203],\n",
       "       grad_fn=<SqueezeBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dataloader))#.to('cuda')\n",
    "model(**batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up:\n",
    "- [ ] Hyperparameters - try a higher LR\n",
    "- [ ] Tooling to report with larger batch size (ie. full data)\n",
    "- [ ] Match up train and eval reporting size\n",
    "\n",
    "What kind of visualisation approach could we use?\n",
    "\n",
    "- The most natural would be to average stats per-epoch\n",
    "- That's not very practical with our dataset size\n",
    "- We could put a limit on num batches per epoch\n",
    "- Since they're shuffled, we'll get a different sample of the data each time\n",
    "- Then set a number of epochs to get the amount of training we desire\n",
    "- Keep the validation set consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
